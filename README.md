# Lumina AI: The Enterprise Knowledge Link ğŸ’

[![Endee](https://img.shields.io/badge/Vector%20DB-Endee-blue.svg)](https://github.com/EndeeLabs/endee)
[![Streamlit](https://img.shields.io/badge/Framework-Streamlit-FF4B4B.svg)](https://streamlit.io)
[![LangChain](https://img.shields.io/badge/Pipeline-LangChain-green.svg)](https://langchain.com)
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org)

## ğŸ“– Project Overview
**Lumina AI** is an Enterprise Retrieval-Augmented Generation (RAG) system designed to enable reliable and context-aware question answering over private organizational data. It integrates **Python**, **LangChain**, and the **Endee Vector Database** to ground large language model (LLM) responses in enterprise-owned documents, APIs, and structured records.

Instead of relying on a language modelâ€™s internal knowledge, Lumina AI retrieves relevant information from trusted data sources and uses it as context for answer generation. This approach improves accuracy, transparency, and reliability when working with private or frequently updated information.

---

## ğŸš© Problem Statement
Large language models are powerful but face important limitations in enterprise environments. They cannot access private or up-to-date organizational data and may generate incorrect or unsupported answers when information is missing. 

These limitations make standalone LLMs unsuitable for applications involving internal documents, APIs, or proprietary knowledge. **Lumina AI** addresses this challenge by retrieving relevant enterprise data from the **Endee Vector Database** and grounding all responses in retrieved evidence, enabling more reliable and explainable AI-driven knowledge access.

---

## ğŸ¯ Key Objectives
*   **Enable semantic search** and question answering over private enterprise data.
*   **Reduce hallucinations** by grounding responses in retrieved context.
*   **Demonstrate practical use of Endee** as a high-performance vector database.
*   **Build a realistic, production-oriented** RAG architecture.

---

## ğŸ—ï¸ Technical Architecture

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  USER INTERFACE                      â”‚
â”‚              (Streamlit - app.py)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Query Processing â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Embedding Generation     â”‚
    â”‚  (HuggingFace Embeddings) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Endee Vector Database    â”‚
    â”‚  (Docker: localhost:8080)  â”‚
    â”‚  - Cosine Similarity       â”‚
    â”‚  - 384-dim Vectors         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Retrieval & Re-ranking â”‚
    â”‚  (Top-K + Confidence)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Response Generation      â”‚
    â”‚  (Context-Grounded RAG)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  System Design

### 1ï¸âƒ£ Multi-Source Data Ingestion
Lumina AI supports ingestion from:
*   **PDF documents**: Policies, manuals, and reports.
*   **Web URLs**: With automatic noise and boilerplate removal.
*   **CSV / Database records**: Structured tabular data.
*   **REST API / JSON responses**: Dynamic data from internal services.

### 2ï¸âƒ£ Semantic Text Processing
*   Text is split into **1000-character chunks** with **200-character overlap**.
*   Metadata is attached to each chunk (source, type, origin) for full traceability.

### 3ï¸âƒ£ Vector Storage with Endee
*   Embeddings are generated using `all-MiniLM-L6-v2` (384-dimensional).
*   Vectors and metadata are stored in **Endee**.
*   **Cosine similarity** is used for high-precision semantic retrieval.

### 4ï¸âƒ£ Retrieval-Augmented Generation (RAG)
*   User queries are embedded and matched against stored vectors.
*   **Top-K (K=15)** relevant chunks are retrieved and filtered to skip noise.
*   Retrieved context is passed to the language model for grounded response generation.

### 5ï¸âƒ£ Interactive User Interface
*   Modern **Streamlit-based** chat interface.
*   Displays retrieved sources and **similarity-based confidence scores**.
*   Built-in tools for clearing and re-indexing data.

---
## ğŸ”— DashBoarad & output<img width="1831" height="761" alt="image" src="https://github.com/user-attachments/assets/0320526f-844a-4072-95ea-f5869ef8f3d7" />
<img width="1831" height="761" alt="image" src="https://github.com/user-attachments/assets/d20f7c76-7464-4963-9981-782111c844a9" />
:

## ğŸ”— Role of Endee Vector Database
Endee serves as the **core semantic memory layer** of Lumina AI. It is utilized for:
*   Storing high-dimensional embeddings.
*   Performing similarity-based semantic search.
*   Managing vector lifecycle (index creation, clearing, re-indexing).

> **Note:** Endee replaces traditional vector stores such as FAISS or Milvus and is the **only** vector database used in this project.

---

## ğŸ› ï¸ Key Features
*   ğŸ” **Semantic Search**: Understands meaning, not just keywords.
*   ğŸ“„ **Multi-Source Ingestion**: PDF, Web, CSV, and API support.
*   ğŸ§  **Grounded Responses**: AI answers only based on your data.
*   ğŸ“Š **Confidence Scoring**: See exactly how relevant the data is.
*   ğŸ§¹ **One-Click Reset**: Easy cleanup of the vector index.
*   ğŸ’¬ **Interactive UI**: Sleek, professional Streamlit interface.

---

## ğŸ“‚ Project Structure
```text
Endee_Assignment/
â”œâ”€â”€ app.py                 # Streamlit application (UI & Logic)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vector_store.py    # Endee client wrapper & fallback
â”‚   â””â”€â”€ ingestion.py       # Data loaders and processors
â”œâ”€â”€ data/
â”‚   â””â”€â”€ customers.csv      # Sample structured data
â”œâ”€â”€ docker-compose.yml     # Endee server configuration
â”œâ”€â”€ requirements.txt       # Project dependencies
â””â”€â”€ README.md              # Documentation
```

---

## ğŸš€ Getting Started

### Prerequisites
*   **Python 3.10+**
*   **Docker Desktop** (Required for Endee Server)

### Setup & Run
1.  **Install dependencies**:
    ```bash
    pip install -r requirements.txt
    ```
2.  **Start Endee server**:
    ```bash
    docker-compose up -d
    ```
3.  **Run the application**:
    ```bash
    streamlit run app.py
    ```

Open your browser at: ğŸ‘‰ [http://localhost:8501](http://localhost:8501)

---

## âœ… Assignment Compliance
*   âœ” **Retrieval-Augmented Generation (RAG)** pipeline implementation.
*   âœ” **Endee** used as the only vector database.
*   âœ” **Multi-source** data ingestion support.
*   âœ” **Semantic retrieval** with confidence scoring.
*   âœ” **LangChain-based** document processing.
*   âœ” **Interactive user interface** with Streamlit.
*   âœ” **Professional documentation** and modular code.

---

## ğŸ”® Future Enhancements
*   **Advanced LLM support**: Native integration for local models like Llama 3.
*   **Metadata filtering**: Filter search results by date or source type.
*   **Authentication**: Secure user login and access control.
*   **Batch Monitoring**: Dashboard for tracking ingestion speeds and query latency.

---

## ğŸ“ Academic & Learning Outcomes
This project demonstrates:
*   Practical integration of **vector databases** in AI workflows.
*   **Enterprise-ready** RAG architecture design.
*   Integration of LLMs with **private, unstructured data**.
*   Clean, modular, and **explainable system design**.

---

## ğŸ“œ License & Credits
*   **Endee Vector Database** â€” [Endee Labs](https://github.com/EndeeLabs/endee)
*   **LangChain** â€” Document processing framework
*   **Sentence Transformers** â€” Embedding models
*   **Streamlit** â€” Web application framework
